{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-21T04:26:43.524657Z","iopub.execute_input":"2024-02-21T04:26:43.524973Z","iopub.status.idle":"2024-02-21T04:26:48.864224Z","shell.execute_reply.started":"2024-02-21T04:26:43.524934Z","shell.execute_reply":"2024-02-21T04:26:48.863021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First we will import the libraries needed.","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense,Flatten, Reshape, LeakyReLU, Dropout, UpSampling2D\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.models import Model\nfrom tensorflow import keras","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:26:48.866001Z","iopub.execute_input":"2024-02-21T04:26:48.866411Z","iopub.status.idle":"2024-02-21T04:27:02.911887Z","shell.execute_reply.started":"2024-02-21T04:26:48.866384Z","shell.execute_reply":"2024-02-21T04:27:02.910811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will read the dataset using a tf.data.Dataset object.","metadata":{}},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus: \n    tf.config.experimental.set_memory_growth(gpu, True)\ndataset = tf.data.Dataset.list_files('/kaggle/input/gan-getting-started/monet_jpg/*')\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:02.913383Z","iopub.execute_input":"2024-02-21T04:27:02.914125Z","iopub.status.idle":"2024-02-21T04:27:04.428775Z","shell.execute_reply.started":"2024-02-21T04:27:02.914095Z","shell.execute_reply":"2024-02-21T04:27:04.427764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will reads the file content as bytes, decodes it as a JPEG image using TensorFlow, and then converts the image to grayscale using the rgb_to_grayscale function.","metadata":{}},{"cell_type":"code","source":"def load_image(x):\n    byte_image = tf.io.read_file(x)\n    img = tf.io.decode_jpeg(byte_image)\n    img = tf.image.rgb_to_grayscale(img)\n    return img","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:04.430830Z","iopub.execute_input":"2024-02-21T04:27:04.431264Z","iopub.status.idle":"2024-02-21T04:27:04.435918Z","shell.execute_reply.started":"2024-02-21T04:27:04.431234Z","shell.execute_reply":"2024-02-21T04:27:04.435007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.map(load_image)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:04.437039Z","iopub.execute_input":"2024-02-21T04:27:04.437315Z","iopub.status.idle":"2024-02-21T04:27:04.532358Z","shell.execute_reply.started":"2024-02-21T04:27:04.437292Z","shell.execute_reply":"2024-02-21T04:27:04.531374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Visuallizing the data:","metadata":{}},{"cell_type":"code","source":"image_gen = dataset.batch(4).as_numpy_iterator()\nplot_img = image_gen.next()\nfig, ax = plt.subplots(ncols = 4, figsize = (20,20))\n\nfor idx,imag in enumerate(plot_img):\n    ax[idx].imshow(np.squeeze(imag))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:04.533638Z","iopub.execute_input":"2024-02-21T04:27:04.534244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def scale_image(image):\n \n    return image / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The next step is to perform data transformation and create batches of images for training the GANs","metadata":{}},{"cell_type":"code","source":"dataset = dataset.map(scale_image)\ndataset = dataset.cache()\ndataset = dataset.shuffle(301)\ndataset = dataset.batch(16)\ndataset = dataset.prefetch(64)\n","metadata":{"execution":{"iopub.status.idle":"2024-02-21T04:27:05.587783Z","shell.execute_reply.started":"2024-02-21T04:27:05.535280Z","shell.execute_reply":"2024-02-21T04:27:05.586825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.as_numpy_iterator().next().shape","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:05.588881Z","iopub.execute_input":"2024-02-21T04:27:05.589193Z","iopub.status.idle":"2024-02-21T04:27:06.089242Z","shell.execute_reply.started":"2024-02-21T04:27:05.589168Z","shell.execute_reply":"2024-02-21T04:27:06.088190Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will build the generator","metadata":{}},{"cell_type":"code","source":"def build_gen():\n    seq_model = Sequential()\n    \n    # Input layer take in random values and reshape it into 16, 16, 128\n    seq_model.add(Dense(16*16*128,input_dim = 16))\n    seq_model.add(LeakyReLU(0.2))\n    seq_model.add(Reshape((16,16,128)))\n    \n    \n    # Upsampling layer 1 that will make it 32,32 128\n    seq_model.add(UpSampling2D())\n    seq_model.add(Conv2D(128,4,padding=\"same\"))\n    seq_model.add(LeakyReLU(0.2))\n    \n    # Upsampling layer 2\n    seq_model.add(UpSampling2D())\n    seq_model.add(Conv2D(128,4,padding=\"same\"))\n    seq_model.add(LeakyReLU(0.2))\n    \n    # Upsampling layer 3\n    seq_model.add(UpSampling2D())\n    seq_model.add(Conv2D(128,4,padding=\"same\"))\n    seq_model.add(LeakyReLU(0.2))\n    \n    # Upsampling layer 4\n    seq_model.add(UpSampling2D())\n    seq_model.add(Conv2D(128,4,padding=\"same\"))\n    seq_model.add(LeakyReLU(0.2))\n\n    \n    # Convolutional layer one \n    seq_model.add(Conv2D(128,4,padding=\"same\"))\n    seq_model.add(LeakyReLU(0.2))\n    \n    # Convolutional layer two for a better pattern detection\n    seq_model.add(Conv2D(128,4,padding=\"same\"))\n    seq_model.add(LeakyReLU(0.2))\n    \n    \n    # Convolutional layer to get to one channel\n    seq_model.add(Conv2D(1,4,padding=\"same\", activation=\"sigmoid\"))\n    return seq_model","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:06.092390Z","iopub.execute_input":"2024-02-21T04:27:06.092691Z","iopub.status.idle":"2024-02-21T04:27:06.103231Z","shell.execute_reply.started":"2024-02-21T04:27:06.092666Z","shell.execute_reply":"2024-02-21T04:27:06.102201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_gen()\nmodel.summary()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-02-21T04:27:06.104287Z","iopub.execute_input":"2024-02-21T04:27:06.104587Z","iopub.status.idle":"2024-02-21T04:27:06.523689Z","shell.execute_reply.started":"2024-02-21T04:27:06.104563Z","shell.execute_reply":"2024-02-21T04:27:06.522790Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image = model.predict(np.random.randn(2,16,1))\nimage","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2024-02-21T04:27:06.524967Z","iopub.execute_input":"2024-02-21T04:27:06.525315Z","iopub.status.idle":"2024-02-21T04:27:09.518283Z","shell.execute_reply.started":"2024-02-21T04:27:06.525283Z","shell.execute_reply":"2024-02-21T04:27:09.517295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(ncols = 2, figsize = (20,20))\n\nfor idx,im in enumerate(image):\n    ax[idx].imshow(np.squeeze(im))\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:09.519422Z","iopub.execute_input":"2024-02-21T04:27:09.519751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will build the discrimenator","metadata":{}},{"cell_type":"code","source":"def build_disc():\n    model = Sequential()\n    \n    # Convenotional layer 1 for pattern detection\n    model.add(Conv2D(32, 5, input_shape = (256,256,1)))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n    # Convenotional layer 2\n    model.add(Conv2D(64, 5))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n    # Convenotional layer 3\n    model.add(Conv2D(128, 5))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n    \n    #  Convenotional layer 4\n    model.add(Conv2D(256, 5))\n    model.add(LeakyReLU(0.2))\n    model.add(Dropout(0.4))\n\n    \n    # Flatten the output\n    model.add(Flatten())\n    model.add(Dropout(0.4))\n    model.add(Dense(1, activation='sigmoid'))\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:10.729049Z","iopub.execute_input":"2024-02-21T04:27:10.729402Z","iopub.status.idle":"2024-02-21T04:27:10.738632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"disc = build_disc()\ndisc.summary()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:10.739760Z","iopub.execute_input":"2024-02-21T04:27:10.740097Z","iopub.status.idle":"2024-02-21T04:27:10.897520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_img.shape\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:10.898623Z","iopub.execute_input":"2024-02-21T04:27:10.898925Z","iopub.status.idle":"2024-02-21T04:27:10.905208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## test the discriminator\n\ndisc.predict(image)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:10.906617Z","iopub.execute_input":"2024-02-21T04:27:10.906966Z","iopub.status.idle":"2024-02-21T04:27:14.902985Z","shell.execute_reply.started":"2024-02-21T04:27:10.906919Z","shell.execute_reply":"2024-02-21T04:27:14.901841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_opt = Adam(learning_rate=0.0001)\ndisc_opt = Adam(learning_rate=0.00001)\ngen_loss = BinaryCrossentropy()\ndisc_loss = BinaryCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:14.904286Z","iopub.execute_input":"2024-02-21T04:27:14.904571Z","iopub.status.idle":"2024-02-21T04:27:14.909652Z","shell.execute_reply.started":"2024-02-21T04:27:14.904547Z","shell.execute_reply":"2024-02-21T04:27:14.908688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we will train the model","metadata":{}},{"cell_type":"code","source":"def train(real, gen_opt, disc_opt, gen_loss, disc_loss):\n    gen = build_gen()\n    disc = build_disc()\n    \n    \n    for epoch in range(10):\n        fake = gen(tf.random.normal((16, 16, 1)), training = False)\n        image = real.as_numpy_iterator().next()\n        with tf.GradientTape() as dtape:\n            # Get the discriminator's predictions for real and fake images\n            real_logits = disc(image, training = True)\n            fake_logits = disc(fake, training = True)\n            \n            realfake_logits = tf.concat([real_logits, fake_logits], axis=0)\n            \n            # Create labels for real and fakes images\n            logit_realfake = tf.concat([tf.zeros_like(real_logits), tf.ones_like(fake_logits)], axis=0)\n            \n            # Add some noise to the TRUE outputs to avoid overfitting\n            noise_real = 0.15*tf.random.uniform(tf.shape(real_logits))\n            noise_fake = -0.15*tf.random.uniform(tf.shape(fake_logits))\n            logit_realfake += tf.concat([noise_real, noise_fake], axis=0)\n            \n            # Calculate loss  \n            total_d_loss = disc_loss(logit_realfake, realfake_logits)\n           \n        # Update the generator's weights and biases\n        dgradients = dtape.gradient(total_d_loss, disc.trainable_variables)\n        disc_opt.apply_gradients(zip(dgradients, disc.trainable_variables))\n            \n        with tf.GradientTape() as gtape:\n\n            fake = gen(tf.random.normal((16, 16, 1)), training = True)\n            # Get the discriminator's predictions for fake images\n            fake_logits = disc(fake, training = False)\n\n            # Calculate the generator's loss\n            g_loss = gen_loss(tf.zeros_like(fake_logits), fake_logits)\n\n        # Update the generator's weights and biases\n        gen_gradients = gtape.gradient(g_loss, gen.trainable_variables)\n        gen_opt.apply_gradients(zip(gen_gradients, gen.trainable_variables))","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:14.911085Z","iopub.execute_input":"2024-02-21T04:27:14.911549Z","iopub.status.idle":"2024-02-21T04:27:14.924112Z","shell.execute_reply.started":"2024-02-21T04:27:14.911517Z","shell.execute_reply":"2024-02-21T04:27:14.923257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(dataset,gen_opt, disc_opt, gen_loss, disc_loss)","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:27:14.925154Z","iopub.execute_input":"2024-02-21T04:27:14.925414Z","iopub.status.idle":"2024-02-21T04:28:01.485147Z","shell.execute_reply.started":"2024-02-21T04:27:14.925392Z","shell.execute_reply":"2024-02-21T04:28:01.483841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator = build_gen()\nimgs = generator.predict(tf.random.normal((7000, 16, 1)))\nfig, ax = plt.subplots(ncols=4, nrows=4, figsize=(10,10))\nfor r in range(4): \n    for c in range(4): \n        ax[r][c].imshow(imgs[(r+1)*(c+1)-1])","metadata":{"execution":{"iopub.status.busy":"2024-02-21T04:28:01.485871Z","iopub.status.idle":"2024-02-21T04:28:01.486217Z","shell.execute_reply.started":"2024-02-21T04:28:01.486055Z","shell.execute_reply":"2024-02-21T04:28:01.486068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"generator.save('generator.h5')\ndiscriminator.save('discriminator.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import PIL\n!mkdir ../images","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(7000):\n    img = array_to_img(imgs[i], scale= True)\n    image.save(\"../images/\" + str(i) + \".jpg\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive(\"/kaggle/working/images\", 'zip', \"/kaggle/images\")","metadata":{},"execution_count":null,"outputs":[]}]}